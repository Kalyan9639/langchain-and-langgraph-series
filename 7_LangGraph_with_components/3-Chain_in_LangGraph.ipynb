{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b46e82c",
   "metadata": {},
   "source": [
    "### Chain Using LangGraph\n",
    "\n",
    "In this section we will see how we can build a simple chain using Langgraph that uses 4 important concepts:\n",
    "\n",
    "* How to use chat messages as our graph state\n",
    "* How to use chat models in graph nodes\n",
    "* How to bind tools to our LLM in chat models\n",
    "* How to execute the tools call in our graph nodes\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6378fe2",
   "metadata": {},
   "source": [
    "### How to use chat messages as our graph state\n",
    "\n",
    "\n",
    "#### 1. Messages\n",
    "\n",
    "We can use messages which can be used to capture different roles within a conversation. LangChain has various messages types including HumanMessage(), AIMessage(), SystemMessage() and ToolMessage(). These represent a message from the user, from chat model, for the chat model to instruct behaviour, and from a tool call.\n",
    "\n",
    "Every message have these important components:\n",
    "\n",
    "* content - content of the message\n",
    "* name - specify the name of the author\n",
    "* response_metadata - optionally, a dict of metadata(e.g., often populated by model provider for AIMessages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c73ddbb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: AI\n",
      "\n",
      "How can i help you?\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "Name: Kalyan\n",
      "\n",
      "I want to learn Machine Learning.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: AI\n",
      "\n",
      "Which specific topic you want to learn?\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from pprint import pprint\n",
    "\n",
    "messages = [AIMessage(content = \"How can i help you?\", name=\"AI\")]\n",
    "messages.append(HumanMessage(content=\"I want to learn Machine Learning.\", name=\"Kalyan\"))\n",
    "messages.append(AIMessage(content=\"Which specific topic you want to learn?\", name=\"AI\"))\n",
    "\n",
    "for message in messages:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14f94b1",
   "metadata": {},
   "source": [
    "##### *We will learn how to append all these different types of messages into our graph state in a specific manner using Reducers in LangGraph*\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f17a02",
   "metadata": {},
   "source": [
    "### 2. Chat Models\n",
    "\n",
    "We can use the sequence of messages as input with the chatmodels using LLM's and OPENAI / GROQ / GEMINI models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e90e261",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Okay, let's dive into Principal Component Analysis (PCA). It's a powerful technique used in machine learning to reduce dimensionality and improve the performance of various machine learning models.\\n\\nPCA is a dimensionality reduction technique that aims to find the most important components of a dataset. It essentially identifies the most significant features that capture the underlying patterns and relationships within the data. By reducing the number of features, PCA can often lead to significant improvements in model accuracy, especially when dealing with high-dimensional data.\\n\\nThe core idea behind PCA is to take the original data and transform it into a lower-dimensional space. This lower-dimensional space represents the most important features, which are the components that are most relevant to the problem. The transformation applied to these features can then be used to create new, simpler features that capture the essence of the data.\\n\\nTo implement PCA, you typically need to:\\n\\n1.  **Choose an appropriate data transformation:** This involves selecting a suitable transformation, such as scaling the data to a standard range or transforming the data into a new feature space.\\n2.  **Apply the transformation:** Apply the chosen transformation to the data.\\n3.  **Calculate the reduced dimensions:** After the transformation, you need to calculate the reduced dimensions, which represent the number of features that are zero.\\n\\nThe resulting reduced dimensions are often called principal components. These principal components can then be used as input to other machine learning models.\\n\\nIn essence, PCA is a powerful tool for finding the most relevant features in a dataset. By reducing the dimensionality of the data, it can improve the performance of machine learning models, leading to better generalization and more accurate predictions.\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "llm = ChatOllama(model = \"gemma3:270m\")\n",
    "\n",
    "messages.append(HumanMessage(content=\"I want to know about Principal Component Analysis and how that is executed or used. no need of code. only explain me clearly on how to use that in 500 words.\"))\n",
    "llm.invoke(messages).content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0286ccfb",
   "metadata": {},
   "source": [
    "\n",
    "### Tools\n",
    "\n",
    "Tools can be integrated with the LLM moddels to interat with external systems. External systems can be API's, third party tools or functions. \n",
    "\n",
    "Whenever a query is asked to the model, it can choose to call the tool and this query is based on the natural language input and this will return an output that matches the tool's schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7be8d3",
   "metadata": {},
   "source": [
    "Now when a tool is used along with the llm, the llm should be able to understand what the tool is and when to use that tool. This can be achieved with the special function / property called `bind_tools` which is used along with llm. \n",
    "\n",
    "\n",
    "This `bind_tools` property works according to the doc-string that we describe during creation of tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "97deb761",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "def date():\n",
    "    \"\"\" Returns the current date, month and year\n",
    "    args: none\n",
    "    return: today's date,month and year of datetime object\n",
    "    \"\"\"\n",
    "    return datetime.now().date()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "17535388",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [date]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dde2bd1",
   "metadata": {},
   "source": [
    "Here, I am using llama3.2 as it is the only downloadable model which supports the tool_binding function in Ollama."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5d6f8553",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOllama(model = \"llama3.2\")\n",
    "llm_tools = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9b4ccd87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"I'm not currently able to share the date and time.\", additional_kwargs={}, response_metadata={'model': 'llama3.2', 'created_at': '2025-09-28T08:02:38.3355673Z', 'done': True, 'done_reason': 'stop', 'total_duration': 8554221300, 'load_duration': 236250500, 'prompt_eval_count': 33, 'prompt_eval_duration': 6194686000, 'eval_count': 13, 'eval_duration': 2111333700, 'model_name': 'llama3.2'}, id='run--82ae0351-2999-4ab7-8c69-d3692c481f13-0', usage_metadata={'input_tokens': 33, 'output_tokens': 13, 'total_tokens': 46})"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"what is the current date and time?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f5144c97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={}, response_metadata={'model': 'llama3.2', 'created_at': '2025-09-28T08:03:01.12756Z', 'done': True, 'done_reason': 'stop', 'total_duration': 22745172800, 'load_duration': 194444100, 'prompt_eval_count': 221, 'prompt_eval_duration': 20351862200, 'eval_count': 12, 'eval_duration': 2195700400, 'model_name': 'llama3.2'}, id='run--8ec0df0b-1179-4b8a-910c-4a3da06e11e2-0', tool_calls=[{'name': 'date', 'args': {}, 'id': 'd63ab087-8501-4a90-8384-40de27679948', 'type': 'tool_call'}], usage_metadata={'input_tokens': 221, 'output_tokens': 12, 'total_tokens': 233})"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_tools.invoke(\"what is the current date and time?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6239bcde",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import TypedDict\n",
    "from typing import Annotated\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_core.messages import AnyMessage\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages:Annotated[list[AnyMessage],add_messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a8af4856",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_call(state:State):\n",
    "    return {\"messages\":[llm_tools.invoke(state[\"messages\"])]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0e4f8618",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import START,END,StateGraph\n",
    "\n",
    "builder = StateGraph(State)\n",
    "\n",
    "builder.add_node(\"llm_tool\",llm_call)\n",
    "\n",
    "builder.add_edge(START,\"llm_tool\")\n",
    "builder.add_edge(\"llm_tool\",END)\n",
    "\n",
    "builder_graph = builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "dcedb710",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = builder_graph.invoke(\n",
    "    {\n",
    "        'messages':\"what is today's date?\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "965bae3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "what is today's date?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  date (e6f9ac32-6f7f-4106-8212-a41ed859f950)\n",
      " Call ID: e6f9ac32-6f7f-4106-8212-a41ed859f950\n",
      "  Args:\n"
     ]
    }
   ],
   "source": [
    "for m in response['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287beb6f",
   "metadata": {},
   "source": [
    "Here, the ai is not giving any output. It is using the tools, but the output after the tool has been used is not displayed back. This is probably because we didn't defined any node for the tools in our graph above.\n",
    "\n",
    " And LangGraph provides a function named `ToolNode` to add the tool node. For condition, we have `tools_condition` in LangGraph which when added to conditional edge of our graph, either directs to the tool node if the llm asks for it, or directs to the END node after the llm response has been generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "fe515370",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import ToolNode\n",
    "from langgraph.prebuilt import tools_condition\n",
    "\n",
    "builder = StateGraph(State)\n",
    "\n",
    "builder.add_node(\"llm_tool\",llm_call)\n",
    "builder.add_node(\"tools\",ToolNode(tools))\n",
    "\n",
    "builder.add_edge(START,\"llm_tool\")\n",
    "builder.add_conditional_edges(\"llm_tool\",tools_condition)\n",
    "builder.add_edge(\"tools\",END)\n",
    "\n",
    "builder_graph = builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "c5a0412c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "today's date?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  date (61db6710-5338-4082-8e08-241074372b41)\n",
      " Call ID: 61db6710-5338-4082-8e08-241074372b41\n",
      "  Args:\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: date\n",
      "\n",
      "2025-09-28\n"
     ]
    }
   ],
   "source": [
    "response = builder_graph.invoke({\"messages\":\"today's date?\"})\n",
    "\n",
    "for m in response['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5acda357",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "udemy-langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
