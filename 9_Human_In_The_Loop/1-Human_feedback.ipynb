{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a66ba6f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\madda\\Desktop\\Udemy\\udemy-langchain\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import SystemMessage,HumanMessage\n",
    "from typing_extensions import TypedDict\n",
    "from typing import Annotated,List\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.messages import AnyMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bcbcb5d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='How can I assist you today?', additional_kwargs={}, response_metadata={'model': 'llama3.2', 'created_at': '2025-10-02T16:38:57.2486094Z', 'done': True, 'done_reason': 'stop', 'total_duration': 2139335500, 'load_duration': 272267600, 'prompt_eval_count': 26, 'prompt_eval_duration': 875309400, 'eval_count': 8, 'eval_duration': 990196000, 'model_name': 'llama3.2'}, id='run--c41e3d9e-05b4-4bc3-bece-ee528217b856-0', usage_metadata={'input_tokens': 26, 'output_tokens': 8, 'total_tokens': 34})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = ChatOllama(model = \"llama3.2\")\n",
    "response = llm.invoke(\"Hi\")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96d441c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining tools\n",
    "\n",
    "def add(a:int, b:int) -> int:\n",
    "    \"\"\"Adds 2 integers and returns an integer\n",
    "    args: 2 integer values\n",
    "    output: addition of given 2 integer numbers\n",
    "    \"\"\"\n",
    "    return a+b\n",
    "\n",
    "def sub(a:int, b:int) -> int:\n",
    "    \"\"\"Subtracts 2 integers and returns an integer\n",
    "    args: 2 integer values\n",
    "    output: subtraction of given 2 integer numbers\n",
    "    \"\"\"\n",
    "    return a-b\n",
    "\n",
    "def multiply(a:int, b:int) -> int:\n",
    "    \"\"\"Multiplies 2 integers and returns an integer\n",
    "    args: 2 integer values\n",
    "    output: mulitplication of given 2 integer numbers\n",
    "    \"\"\"\n",
    "    return a*b\n",
    "\n",
    "def divide(a:int, b:int) -> float:\n",
    "    \"\"\"Divides 2 integers and returns a float value\n",
    "    args: 2 integer values\n",
    "    output: division of given 2 integer numbers\n",
    "    \"\"\"\n",
    "    return a/b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5420c992",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [add,sub,multiply,divide]\n",
    "\n",
    "llm_with_tools = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7f3f1274",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={}, response_metadata={'model': 'llama3.2', 'created_at': '2025-10-02T16:24:57.9155608Z', 'done': True, 'done_reason': 'stop', 'total_duration': 43667139400, 'load_duration': 177429800, 'prompt_eval_count': 416, 'prompt_eval_duration': 39618792600, 'eval_count': 22, 'eval_duration': 3869698700, 'model_name': 'llama3.2'}, id='run--ba3c6515-3a31-407a-8fb6-4e56240c7729-0', tool_calls=[{'name': 'add', 'args': {'a': '2', 'b': '3'}, 'id': 'f003f3f3-058c-42c9-8d55-f06bef1e6757', 'type': 'tool_call'}], usage_metadata={'input_tokens': 416, 'output_tokens': 22, 'total_tokens': 438})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_with_tools.invoke(\"addition of 2 and 3 is:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2da18321",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    messages:Annotated[List[AnyMessage],add_messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d88f4f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_call(state:State):\n",
    "    return {'messages':[llm_with_tools.invoke(state['messages'])]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf84ee41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph,START,END\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "\n",
    "builder = StateGraph(State)\n",
    "\n",
    "builder.add_node(\"llm_call\",llm_call)\n",
    "builder.add_node(\"tools\",ToolNode(tools))\n",
    "\n",
    "builder.add_edge(START,\"llm_call\")\n",
    "builder.add_conditional_edges('llm_call',tools_condition)\n",
    "builder.add_edge('tools','llm_call')\n",
    "builder.add_edge('llm_call',END)\n",
    "\n",
    "memory = MemorySaver()\n",
    "builder_graph = builder.compile(checkpointer=memory, interrupt_before=[\"llm_call\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "90561d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {'configurable':{'thread_id':'12'}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "106cbf50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "response = builder_graph.invoke({\"messages\":\"addition of 2 and 2 is?\"},config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5c1889b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "addition of 2 and 2 is?\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "addition of 2 and 2 is?\n"
     ]
    }
   ],
   "source": [
    "for m in response['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7d146f9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StateSnapshot(values={'messages': [HumanMessage(content='addition of 2 and 2 is?', additional_kwargs={}, response_metadata={}, id='6e1c9846-ca94-41d3-8432-6a30a25eaf86'), HumanMessage(content='addition of 2 and 2 is?', additional_kwargs={}, response_metadata={}, id='3aa91a78-3dd5-447a-aed9-fb17f94f921b')]}, next=('llm_call',), config={'configurable': {'thread_id': '12', 'checkpoint_ns': '', 'checkpoint_id': '1f09fae5-1956-6c77-8002-035403adafc6'}}, metadata={'source': 'loop', 'step': 2, 'parents': {}, 'thread_id': '12'}, created_at='2025-10-02T16:39:09.035839+00:00', parent_config={'configurable': {'thread_id': '12', 'checkpoint_ns': '', 'checkpoint_id': '1f09fae5-1948-6e05-8001-1e2c8242c696'}}, tasks=(PregelTask(id='69042cdb-1c43-53f2-f6db-c224d12b4b3f', name='llm_call', path=('__pregel_pull', 'llm_call'), error=None, interrupts=(), state=None, result=None),), interrupts=())"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "builder_graph.get_state(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b90d3ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [HumanMessage(content='addition of 2 and 2 is?', additional_kwargs={}, response_metadata={}, id='6e1c9846-ca94-41d3-8432-6a30a25eaf86'),\n",
      "              HumanMessage(content='addition of 2 and 2 is?', additional_kwargs={}, response_metadata={}, id='3aa91a78-3dd5-447a-aed9-fb17f94f921b')]}\n"
     ]
    }
   ],
   "source": [
    "for m in builder_graph.stream(None, stream_mode='values',config=config):\n",
    "    pprint(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a37f998",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "udemy-langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
