{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5926e72",
   "metadata": {},
   "source": [
    "### 5. Generator-Evaluator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0635682e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import TypedDict, Literal\n",
    "from typing import Annotated, List\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "# from langchain_groq import ChatGroq\n",
    "from langchain_ollama import ChatOllama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fb13579e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello there! How can I help you today?\\n', additional_kwargs={}, response_metadata={'model': 'gemma3:270m', 'created_at': '2025-10-01T16:39:36.6440311Z', 'done': True, 'done_reason': 'stop', 'total_duration': 402128000, 'load_duration': 160591700, 'prompt_eval_count': 10, 'prompt_eval_duration': 35853700, 'eval_count': 12, 'eval_duration': 204818300, 'model_name': 'gemma3:270m'}, id='run--d3168711-fbe2-41df-b1f3-1f7f3485e2a8-0', usage_metadata={'input_tokens': 10, 'output_tokens': 12, 'total_tokens': 22})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from dotenv import load_dotenv\n",
    "# load_dotenv()\n",
    "# import os\n",
    "\n",
    "# llm = ChatGroq(model=\"llama-3.3-70b-versatile\")\n",
    "llm = ChatOllama(model = \"gemma3:270m\")\n",
    "response = llm.invoke(\"HI\")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "429277b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    topic:str\n",
    "    generated_joke: str\n",
    "    feedback:str\n",
    "    funny_or_not: str\n",
    "\n",
    "class Feedback(BaseModel):\n",
    "    grade:Literal['funny', 'not funny'] = Field(description=\"Whether the joke is funny or not\")\n",
    "    feedback:str=Field(description=\"If the joke is not funny, provide constructive feedback on how to make it funnier\")\n",
    "\n",
    "\n",
    "evaluator = llm.with_structured_output(Feedback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7b1438dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_call_generator(state:State):\n",
    "    \"\"\"Generates a joke based on the topic provided in the state.\"\"\"\n",
    "    if state.get('feedback'):\n",
    "        msg = llm.invoke(f\"Write a joke about {state['topic']} but take into account the feedback: {state['feedback']}\")\n",
    "    else:\n",
    "        msg = llm.invoke(f\"Write a joke about {state['topic']}\")\n",
    "        return({\"generated_joke\": msg.content})\n",
    "\n",
    "def llm_call_evaluator(state:State):\n",
    "    \"\"\"Evaluates the generated joke and provides feedback.\"\"\"\n",
    "    msg = evaluator.invoke(f\"Here is a joke: {state['generated_joke']}. Is it funny? If not, provide constructive feedback on how to make it funnier.\")\n",
    "    return({\"funny_or_not\": msg.grade, \"feedback\": msg.feedback})\n",
    "\n",
    "# Conditional edge function to route back the logic to generator if the joke is not funny\n",
    "def route_joke(state:State):\n",
    "    \"\"\"Returns back to the generator or to the end based upon the feedback from the evaluator.\"\"\"\n",
    "\n",
    "    if state['funny_or_not'] == 'not funny':\n",
    "        return 'not_funny'\n",
    "    elif state['funny_or_not'] == 'funny':\n",
    "        return 'funny'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2c611606",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph,START,END\n",
    "\n",
    "builder = StateGraph(State)\n",
    "\n",
    "builder.add_node(\"generator\",llm_call_generator)\n",
    "builder.add_node(\"evaluator\",llm_call_evaluator)\n",
    "builder.add_node(\"route_joke\",route_joke)\n",
    "\n",
    "builder.add_edge(START,\"generator\")\n",
    "builder.add_edge(\"generator\",\"evaluator\")\n",
    "builder.add_conditional_edges(\"evaluator\",route_joke,{'not_funny':'generator', 'funny':END})\n",
    "builder.add_edge(\"route_joke\",END)\n",
    "\n",
    "builder_graph = builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "976429d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Why don't ice cream lovers go to the beach? \n",
       "... Because they're always getting ice cream!\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Markdown\n",
    "\n",
    "response = builder_graph.invoke({'topic':'ice cream'})\n",
    "Markdown(response['generated_joke'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a477df25",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "udemy-langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
